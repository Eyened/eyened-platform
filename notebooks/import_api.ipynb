{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Import API - HRFAV Fundus Dataset\n",
    "\n",
    "This notebook demonstrates how to import images using the `/import/image` api.\n",
    "\n",
    "For more information: https://eyened.github.io/eyened-platform/getting_started/\n",
    "\n",
    "The underlying API calls are formulated like this:\n",
    "\n",
    "1. You need to log in to obtain a session cookie via /api/auth/login-password:\n",
    "\n",
    "```bash\n",
    "curl -X POST \"http://<host>:<port>/api/auth/login-password\" \\\n",
    "  -d '{\n",
    "    \"username\": \"<admin_username>\",\n",
    "    \"password\": \"<admin_password>\",\n",
    "    \"remember_me\": false\n",
    "  }' \\\n",
    "  -c cookies.txt\n",
    "```  \n",
    "\n",
    "This stores your session in cookies.txt\n",
    "\n",
    "2. To add an image, call /api/import/image\n",
    "\n",
    "```bash\n",
    "  curl -X POST \"http://<host>:<port>/api/import/image\" \\\n",
    "  -b cookies.txt \\\n",
    "  -d '{\n",
    "    \"data\": <image_payload>,\n",
    "    \"options\": {\n",
    "      \"create_project\": true,\n",
    "      \"create_patients\": true,\n",
    "      \"create_studies\": true,\n",
    "      \"create_series\": true,\n",
    "      \"include_stack_trace\": true\n",
    "    }\n",
    "  }'\n",
    "  ```\n",
    "\n",
    "  However, this notebooks makes use of the requests library in python and the `ImageImporter` utility class in `eyened_orm.importer.image_importer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from eyened_orm.importer.image_importer import ImageImporter\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import download_and_extract_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create importer\n",
    "\n",
    "The importer is a utility class that wraps the API calls using a session for authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for production settings\n",
    "# env_path = Path.cwd().parent / \"orm\" / \"eyened_orm\" / \"environments\" / \"prod_wr.env\"\n",
    "# load_dotenv(env_path)\n",
    "# importer = ImageImporter(\n",
    "#     admin_username=os.getenv(\"ADMIN_USERNAME\"),\n",
    "#     admin_password=os.getenv(\"ADMIN_PASSWORD\"),\n",
    "#     images_basepath=os.getenv(\"IMAGES_BASEPATH\"),\n",
    "#     host=os.getenv(\"HOST\"),\n",
    "#     port=os.getenv(\"PORT\"),\n",
    "# )\n",
    "\n",
    "# development settings\n",
    "env_path = Path.cwd().parent / \"dev\" / \".env\"\n",
    "load_dotenv(env_path)\n",
    "importer = ImageImporter(\n",
    "    admin_username=os.getenv(\"ADMIN_USERNAME\"),\n",
    "    admin_password=os.getenv(\"ADMIN_PASSWORD\"),\n",
    "    images_basepath=os.getenv(\"IMAGES_BASEPATH\"),\n",
    "    host=\"localhost\",\n",
    "    port=os.getenv(\"DEV_NGINX_PORT\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract HRFAV dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_dir = Path(importer.images_basepath) / \"hrfav\"\n",
    "if not extract_dir.exists():\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    download_and_extract_dataset(\n",
    "        \"https://www5.cs.fau.de/fileadmin/research/datasets/fundus-images/all.zip\",\n",
    "        extract_dir,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 45 images.\n"
     ]
    }
   ],
   "source": [
    "# Set up project information\n",
    "project_name = \"HRFAV\"\n",
    "images_dir = extract_dir / \"images\"\n",
    "image_paths = list(images_dir.glob(\"*.jpg\", case_sensitive=False))\n",
    "\n",
    "print(f\"Found {len(image_paths)} images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Images \n",
    "\n",
    "We'll now import each image individually using the `/import/image` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5019da3ad5c457c98a54ee0bb5b027b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Importing images:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For tracking results\n",
    "import_results = []\n",
    "for idx, img_path in enumerate(tqdm(image_paths, desc=\"Importing images\")):\n",
    "\n",
    "    # Create the payload\n",
    "\n",
    "    # important:the path should be relative to the images_basepath\n",
    "    path = str(img_path.relative_to(importer.images_basepath))\n",
    "    # just for demo, laterality needs to be set to either \"R\" or \"L\" (not the actual laterality for these images)\n",
    "    laterality = \"R\" if idx % 2 == 0 else \"L\"\n",
    "    # just for demo, we need to indicate a patient_identifier for each image\n",
    "    patient_identifier = f\"Patient_{idx//2}\"\n",
    "    # just for demo, we need to indicate a study_date for each image\n",
    "    study_date = date.today().isoformat()\n",
    "\n",
    "    image_payload = {\n",
    "        \"project_name\": project_name,\n",
    "        \"patient_identifier\": patient_identifier,\n",
    "        \"study_date\": study_date,\n",
    "        \"image\": path,\n",
    "        \"image_props\": {\"OldPath\": img_path.stem, \"Laterality\": laterality},\n",
    "    }\n",
    "\n",
    "    result = importer.import_image(image_payload)\n",
    "    import_results.append(result)\n",
    "\n",
    "    # If an error occurred, print it but continue with the next image\n",
    "    if not result[\"success\"]:\n",
    "        print(f\"Error importing {img_path.name}: {result['error']}\")\n",
    "        print(result[\"stack_trace\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 45\n",
      "Successfully imported: 45\n",
      "Failed imports: 0\n"
     ]
    }
   ],
   "source": [
    "# Summarize the import results\n",
    "successful_imports = [r for r in import_results if r[\"success\"]]\n",
    "failed_imports = [r for r in import_results if not r[\"success\"]]\n",
    "\n",
    "print(f\"Total images: {len(image_paths)}\")\n",
    "print(f\"Successfully imported: {len(successful_imports)}\")\n",
    "print(f\"Failed imports: {len(failed_imports)}\")\n",
    "\n",
    "if failed_imports:\n",
    "    print(\"\\nFailed imports:\")\n",
    "    for fail in failed_imports:\n",
    "        print(f\"  {fail['image_path']}: {fail['error']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
