{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "import json\n",
    "import base64\n",
    "import gzip\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sqlalchemy import select, func\n",
    "from eyened_orm import (\n",
    "    ImageInstance,\n",
    "    Modality,\n",
    "    Feature,\n",
    "    Annotation,\n",
    "    AnnotationData,\n",
    "    AnnotationType,\n",
    "    Segmentation\n",
    ")\n",
    "from eyened_orm.Segmentation import Datatype, DataRepresentation\n",
    "from eyened_orm.db import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating engine with connection string mysql+pymysql://root:t8S3sBPyxTFfDEsfucFBKDU2S7G7Xtm5@eyened-gpu:22114/eyened_database\n"
     ]
    }
   ],
   "source": [
    "database = Database('../dev/.env')\n",
    "session = database.create_session()\n",
    "# config = get_config(\"dev\")\n",
    "# DBManager.init(config)\n",
    "# session = DBManager.get_session()\n",
    "# annotation_zarr_storage_manager = AnnotationZarrStorageManager(\n",
    "#     config.annotations_zarr_store\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_with_annotation_type(annotation_type_ids, where=None):\n",
    "    #\n",
    "    query = (\n",
    "        select(Annotation, AnnotationData, ImageInstance)\n",
    "        .join_from(Annotation, AnnotationData, isouter=True)\n",
    "        .join_from(Annotation, ImageInstance, isouter=True)\n",
    "        .where(~Annotation.Inactive & (Annotation.AnnotationTypeID.in_(annotation_type_ids)))\n",
    "    )\n",
    "    \n",
    "    if where is not None:\n",
    "        query = query.where(where)\n",
    "    \n",
    "    all_annots = session.execute(\n",
    "        query\n",
    "        .order_by(func.random())\n",
    "        .limit(5)\n",
    "    ).all()\n",
    "    all_annots = [(annot, annot_data, image_instance) for annot, annot_data, image_instance in all_annots if annot_data is not None]\n",
    "    return all_annots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC ANNOTATIONS\n",
    "# 13 binary mask annotations\n",
    "# 14 probability annotations\n",
    "# 20 oct binary mask annotations\n",
    "# 4 label numbers\n",
    "def open_data(dpath, db_res=None):\n",
    "    if dpath.suffix == \".gz\":\n",
    "        assert db_res is not None, \"db_res is required for .gz files\"\n",
    "        with gzip.open(dpath, 'rb') as f:\n",
    "            im = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "            im = im.reshape(db_res) # HWD\n",
    "            # transpose to DHW\n",
    "            im = im.transpose(2,0,1)\n",
    "    else:\n",
    "        im = Image.open(dpath)\n",
    "\n",
    "        # if db_res[:2] != im.size:\n",
    "            # raise RuntimeError(f'Found shape {im.size} != {db_res} for {dpath}')\n",
    "\n",
    "        if im.mode != \"L\":\n",
    "            print(f\"Found mode {im.mode} for {dpath}\")\n",
    "            im = im.convert('L')\n",
    "\n",
    "        im = np.array(im)\n",
    "        \n",
    "    if len(im.shape) == 2:\n",
    "        im = im[None,...].astype(np.uint8)\n",
    "    \n",
    "    if len(im.shape) != 3:\n",
    "        raise RuntimeError(f'Found shape {im.shape} for {dpath}')\n",
    "\n",
    "    return im # DHW\n",
    "\n",
    "\n",
    "def convert_one_annotation_basic(annot, annot_data, image_instance):\n",
    "\n",
    "    res_db = (image_instance.Rows_y, image_instance.Columns_x, image_instance.NrOfFrames)\n",
    "\n",
    "    try:\n",
    "        im = open_data(annot_data.path, res_db)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f'Error opening {annot_data.path}: {e}') from e\n",
    "    \n",
    "    if len(im.shape) != 3:\n",
    "        raise RuntimeError(f'Found shape {im.shape} for {annot_data.path}')\n",
    "\n",
    "    depth, height, width = im.shape\n",
    "    segmentation = Segmentation(\n",
    "        Depth=depth,\n",
    "        Height=height,\n",
    "        Width=width,\n",
    "        SparseAxis=0,\n",
    "        ScanIndices=None,\n",
    "        ImageProjectionMatrix=None,\n",
    "        DataRepresentation=DataRepresentation.Binary,\n",
    "        DataType=Datatype.R8UI,\n",
    "        ImageInstanceID=image_instance.ImageInstanceID,\n",
    "        CreatorID=annot.CreatorID,\n",
    "        FeatureID = annot.FeatureID\n",
    "    )\n",
    "\n",
    "    session.add(segmentation)\n",
    "    session.flush([segmentation])\n",
    "\n",
    "    segmentation.write_data(im)\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "def convert_annotations_basic(annotation_type_id):\n",
    "    elems = get_annotations_with_annotation_type([annotation_type_id])\n",
    "    annotations = []\n",
    "    segmentations = []\n",
    "\n",
    "    for annot, annot_data, image_instance in elems:\n",
    "        # if annot_data is None\n",
    "        # assert annot_data.path.suffix == \".png\", annot_data.path\n",
    "\n",
    "        try:\n",
    "            segmentation = convert_one_annotation_basic(annot, annot_data, image_instance)\n",
    "        except Exception as e:\n",
    "            print(f'Error converting {annot_data.path}: {e}')\n",
    "            continue\n",
    "        \n",
    "        segmentations.append(segmentation)\n",
    "        annotations.append(annot)\n",
    "\n",
    "    session.commit()\n",
    "    return annotations, segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations, segmentations = convert_annotations_basic(13)\n",
    "# print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations, segmentations = convert_annotations_basic(14)\n",
    "# fine but threshold set to 0 can make the annotations look all white.\n",
    "# still stored correctly in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations, segmentations = convert_annotations_basic(20)\n",
    "# issue with displaying png series\n",
    "# could not check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for annot, seg in zip(annotations, segmentations):\n",
    "#     print(annot.AnnotationID, seg.SegmentationID, seg.ImageInstanceID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R/G masks\n",
    "# 2, 3, 5\n",
    "def convert_annotations_rgmasks(annotation_type_id, where=None):\n",
    "    elems = get_annotations_with_annotation_type([annotation_type_id], where=where)\n",
    "    annotations = []\n",
    "    segmentations = []\n",
    "    # ignore Vessel masks here. They will be inserted with the Artery/Vein annotations\n",
    "    for annot, annot_data, image_instance in elems:\n",
    "        # if annot_data is None\n",
    "        assert annot_data.path.suffix == \".png\", annot_data.path\n",
    "\n",
    "        if image_instance is None:\n",
    "            print(\n",
    "                f\"Found image_instance is None for {annot_data.path}, annot_id: {annot.AnnotationID}\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        res_db = (image_instance.Columns_x, image_instance.Rows_y)\n",
    "\n",
    "        im = Image.open(annot_data.path)\n",
    "        rs_im = im.size\n",
    "\n",
    "        if res_db != rs_im:\n",
    "            print(f\"Found shape {rs_im} != {res_db} for {annot_data.path}\")\n",
    "            continue\n",
    "        width, height = im.size\n",
    "        print(height, width)\n",
    "            \n",
    "        if im.mode == 'RGBA':\n",
    "            im = im.convert(\"RGB\")\n",
    "\n",
    "        im = np.array(im)\n",
    "        new_im = np.zeros((1, height, width), np.uint8)\n",
    "        if len(im.shape) == 3:\n",
    "            # both red and green channels\n",
    "            new_im[0, im[...,0] > 0] = 1\n",
    "            new_im[0, im[...,1] > 0] = 2\n",
    "            new_im[0, (im[...,0] > 0) & (im[...,1] > 0)] = 3\n",
    "        else:\n",
    "            # only R channel\n",
    "            new_im[0, im > 0] = 1\n",
    "\n",
    "        segmentation = Segmentation(\n",
    "            Depth=1,\n",
    "            Height=height,\n",
    "            Width=width,\n",
    "            SparseAxis=0,\n",
    "            ScanIndices=None,\n",
    "            ImageProjectionMatrix=None,\n",
    "            DataRepresentation=DataRepresentation.DualBitMask,\n",
    "            DataType=Datatype.R8UI,\n",
    "            ImageInstanceID=image_instance.ImageInstanceID,\n",
    "            CreatorID=annot.CreatorID,\n",
    "            FeatureID = annot.FeatureID\n",
    "        )\n",
    "\n",
    "        session.add(segmentation)\n",
    "        session.flush([segmentation])\n",
    "\n",
    "        print(new_im.shape)\n",
    "        segmentation.write_data(new_im)\n",
    "\n",
    "        segmentations.append(segmentation)\n",
    "        annotations.append(annot)\n",
    "\n",
    "    session.commit()\n",
    "    return segmentations, annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1934 2576\n",
      "(1, 1934, 2576)\n",
      "array_name: uint8_1_1934_2576.zarr\n",
      "496 768\n",
      "(1, 496, 768)\n",
      "array_name: uint8_1_496_768.zarr\n",
      "1934 1960\n",
      "(1, 1934, 1960)\n",
      "array_name: uint8_1_1934_1960.zarr\n",
      "1934 1960\n",
      "(1, 1934, 1960)\n",
      "array_name: uint8_1_1934_1960.zarr\n",
      "1934 1960\n",
      "(1, 1934, 1960)\n",
      "array_name: uint8_1_1934_1960.zarr\n"
     ]
    }
   ],
   "source": [
    "segmentations, annotations = convert_annotations_rgmasks(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16666 188 1208653\n",
      "175153 189 2215229\n",
      "18637 190 1223900\n",
      "399652 191 1224812\n",
      "13752 192 1237440\n"
     ]
    }
   ],
   "source": [
    "for annot, seg in zip(annotations, segmentations):\n",
    "    print(annot.AnnotationID, seg.SegmentationID, seg.ImageInstanceID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# artery-vein annotations\n",
    "def convert_av_annotations():\n",
    "    import json\n",
    "    import base64\n",
    "\n",
    "    feature_map = {\n",
    "        'Artery': Feature.by_name(session, 'Arteries').FeatureID,\n",
    "        'Vein': Feature.by_name(session, 'Veins').FeatureID,\n",
    "        'Vessel': Feature.by_name(session, 'Unknown Vessel').FeatureID,\n",
    "    }\n",
    "\n",
    "    annotations = []\n",
    "    segmentations = []\n",
    "    for annot, annot_data, image_instance in get_annotations_with_annotation_type([9]):\n",
    "        # if annot_data is None\n",
    "        assert annot_data.path.suffix == \".json\", annot_data.path\n",
    "\n",
    "        if image_instance is None:\n",
    "            print(f\"Found image_instance is None for {annot_data.path}, annot_id: {annot.AnnotationID}\")\n",
    "            continue\n",
    "\n",
    "        with open(annot_data.path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        if 'maskID' not in data:\n",
    "            raise RuntimeError(f\"Found maskID not in data for {annot_data.path}, keys are {data.keys()}\")\n",
    "            \n",
    "\n",
    "        mask_annot = Annotation.by_id(session, data['maskID'])\n",
    "        if mask_annot is None:\n",
    "            print(f\"Found mask is None for {annot_data.path}, annot_id: {annot.AnnotationID}\")\n",
    "            continue\n",
    "\n",
    "        assert mask_annot.ImageInstance is not None\n",
    "            \n",
    "        vessels_segmentation = convert_one_annotation_basic(mask_annot, mask_annot.AnnotationData[0], mask_annot.ImageInstance)\n",
    "\n",
    "\n",
    "        # img_size = (annot[2].Columns_x, annot[2].Rows_y)\n",
    "        width, height = image_instance.Columns_x, image_instance.Rows_y\n",
    "        if 'branches' not in data:\n",
    "            print(f\"Found branches not in data for {annot_data.path}, keys are {data.keys()}\")\n",
    "            continue\n",
    "\n",
    "        for branch in data['branches']:\n",
    "            print(branch.keys())\n",
    "            print(branch['vesselType'])\n",
    "            drawing = branch['drawing'][22:]\n",
    "            drawing = base64.b64decode(drawing)\n",
    "            # drawing = np.frombuffer(drawing, dtype=np.uint8)\n",
    "            drawing = Image.open(BytesIO(drawing))\n",
    "            drawing = np.array(drawing)[:, :, 0]\n",
    "            drawing = drawing.reshape(height, width)\n",
    "            drawing = drawing[None,...]\n",
    "\n",
    "            feature_id = feature_map[branch['vesselType']]\n",
    "\n",
    "            # put in Zarr\n",
    "            segmentation = Segmentation(\n",
    "                Depth=1,\n",
    "                Height=height,\n",
    "                Width=width,\n",
    "                SparseAxis=0,\n",
    "                ScanIndices=None,\n",
    "                ImageProjectionMatrix=None,\n",
    "                DataRepresentation=DataRepresentation.Binary,\n",
    "                DataType=Datatype.R8UI,\n",
    "                ImageInstanceID=image_instance.ImageInstanceID,\n",
    "                CreatorID=annot.CreatorID,\n",
    "                FeatureID=feature_id,\n",
    "                ReferenceSegmentationID=vessels_segmentation.SegmentationID\n",
    "            )\n",
    "\n",
    "            session.add(segmentation)\n",
    "            session.flush([segmentation])\n",
    "\n",
    "            segmentation.write_data(drawing)\n",
    "\n",
    "            annotations.append(annot)\n",
    "            segmentations.append(segmentation)\n",
    "\n",
    "    session.commit()\n",
    "    return annotations, segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/viewer/eyened_platform/orm/eyened_orm/base.py:196: SAWarning: relationship 'Feature.FeatureAssociations' will copy column Feature.FeatureID to column CompositeFeature.ParentFeatureID, which conflicts with relationship(s): 'FeatureFeatureLink.Child' (copies Feature.FeatureID to CompositeFeature.ParentFeatureID). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"Child\"' to the 'Feature.FeatureAssociations' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  return session.scalar(stmt)\n",
      "/home/jose/viewer/eyened_platform/orm/eyened_orm/base.py:196: SAWarning: relationship 'Feature.ChildFeatureAssociations' will copy column Feature.FeatureID to column CompositeFeature.ChildFeatureID, which conflicts with relationship(s): 'FeatureFeatureLink.Feature' (copies Feature.FeatureID to CompositeFeature.ChildFeatureID). If this is not the intention, consider if these relationships should be linked with back_populates, or if viewonly=True should be applied to one or more if they are read-only. For the less common case that foreign key constraints are partially overlapping, the orm.foreign() annotation can be used to isolate the columns that should be written towards.   To silence this warning, add the parameter 'overlaps=\"Feature\"' to the 'Feature.ChildFeatureAssociations' relationship. (Background on this warning at: https://sqlalche.me/e/20/qzyx) (This warning originated from the `configure_mappers()` process, which was invoked automatically in response to a user-initiated operation.)\n",
      "  return session.scalar(stmt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found mode RGBA for /mnt/oogergo/eyened/eyened_platform/annotations/255106/107366_0.png\n",
      "array_name: uint8_1_1080_1620.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Artery\n",
      "array_name: uint8_1_1080_1620.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vein\n",
      "array_name: uint8_1_1080_1620.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vessel\n",
      "array_name: uint8_1_1080_1620.zarr\n",
      "Found mode RGBA for /mnt/oogergo/eyened/eyened_platform/annotations/198404/107370_0.png\n",
      "array_name: uint8_1_576_768.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Artery\n",
      "array_name: uint8_1_576_768.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vein\n",
      "array_name: uint8_1_576_768.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vessel\n",
      "array_name: uint8_1_576_768.zarr\n",
      "Found mode RGB for /mnt/oogergo/eyened/eyened_platform/annotations/320105/66803_0.png\n",
      "array_name: uint8_1_1632_2464.zarr\n",
      "Found branches not in data for /mnt/oogergo/eyened/eyened_platform/annotations/320105/96415_0.json, keys are dict_keys(['maskID'])\n",
      "Found mode RGBA for /mnt/oogergo/eyened/eyened_platform/annotations/1689254/399062_0.png\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Artery\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vein\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vessel\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "Found mode RGBA for /mnt/oogergo/eyened/eyened_platform/annotations/1689254/398973_0.png\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Artery\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vein\n",
      "array_name: uint8_1_1024_1024.zarr\n",
      "dict_keys(['id', 'vesselType', 'drawing', 'color'])\n",
      "Vessel\n",
      "array_name: uint8_1_1024_1024.zarr\n"
     ]
    }
   ],
   "source": [
    "annotations, segmentations = convert_av_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107367 164 521734\n",
      "107367 165 521734\n",
      "107367 166 521734\n",
      "107371 168 803696\n",
      "107371 169 803696\n",
      "107371 170 803696\n",
      "399362 173 2230692\n",
      "399362 174 2230692\n",
      "399362 175 2230692\n",
      "399273 177 2230603\n",
      "399273 178 2230603\n",
      "399273 179 2230603\n"
     ]
    }
   ],
   "source": [
    "for annot, seg in zip(annotations, segmentations):\n",
    "    print(annot.AnnotationID, seg.SegmentationID, seg.ImageInstanceID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
